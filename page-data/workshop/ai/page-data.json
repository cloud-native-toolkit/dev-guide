{"componentChunkName":"component---src-pages-workshop-ai-index-mdx","path":"/workshop/ai/","result":{"pageContext":{"frontmatter":{"title":"Workshop - Deploy an Artificial Intelligence Microservice"},"relativePagePath":"/workshop/ai/index.mdx","titleType":"page","MdxNode":{"id":"a1f2504d-c19f-5106-9388-0a8ff2d8e13f","children":[],"parent":"7265a496-3ed5-54a0-af65-810f99967eb8","internal":{"content":"---\ntitle: Workshop - Deploy an Artificial Intelligence Microservice\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nDeploy an Artificial Intelligence Microservice\n\n</PageDescription>\n\n1. Prerequisites\n    - The instructor should [Setup Workshop Environment](/workshop/setup)\n    - The student should [Setup CLI and Terminal Shell](/workshop/terminal)\n\n1. Instructor will provide the following info:\n    - OpenShift Console URL (OCP_CONSOLE_URL)\n    - The username and password for OpenShift and Git Server (default values are user01, user02, etc.. for users and `password` for password).\n\n1. Set `TOOLKIT_USERNAME` environment variable.\n   If you are participation in a workshop replace `userdemo` with your assigned username (ex. `user01`).\n    ```bash\n    TOOLKIT_USERNAME=userdemo\n    ```\n\n1. Login to OpenShift using `oc`\n    - If using IBM Cloud cluster then login with your IBM account email and IAM API Key or Token by using the **Copy Login Command**\n        ![Login](../images/login.jpg)\n    - If using a cluster that was configured with the workshop scripts outside IBM Cloud then use respective assigned username (ex. `user01`), and the password is `password`\n    ```bash\n    oc login $OCP_URL -u $TOOLKIT_USERNAME -p password\n    ```\n\n1. Set `TOOLKIT_PROJECT` environment variable\n   If you are participation in a workshop replace `projectdemo` based on your assigned username (ex. `project01`).\n    ```bash\n    TOOLKIT_PROJECT=projectdemo\n    ```\n\n1. Create a project/namespace using your project as prefix, and `-dev` and suffix\n    ```bash\n    oc sync $TOOLKIT_PROJECT-dev\n    ```\n\n1. Fork application template git repo\n    - Open Developer Dashboard from the OpenShift Console\n        ![Developer Dashboard](../images/developer-dashboard.jpg)\n    - Select Starter Kits\n        ![Starter Kits](../images/starter-kits-ai.jpg)\n    - Select One in our case **Artificial Intelligence Microservice**\n    - Click Fork\n    - Login into GIT Sever using the provided username and password (ie `userdemo` and `password`)\n    - Click **Fork Repository**\n\n1. Setup environment variable `GIT_URL` for the git url using the value from previous step or as following.\n        **Note:** We are including username/password in git url for simplicity of this lab. You would **NOT** want to do this in your development environment.\n    ```bash\n    GIT_REPO=ai-model-object-detector\n    GIT_URL=http://${TOOLKIT_USERNAME}:password@$(oc get route -n tools gogs --template='{{.spec.host}}')/${TOOLKIT_USERNAME}/${GIT_REPO}\n    echo GIT_URL=${GIT_URL}\n\n    ```\n\n1. Clone the git repository and change directory\n    ```bash\n    cd $HOME\n    git clone $GIT_URL app\n    cd app\n\n    ```\n\n1. Create a Tekton pipeline for the application\n    ```bash\n    oc pipeline --tekton\n    ```\n    - Use down/up arrow and select `ibm-general`\n    - Enter **n** and hit Enter to disable image scanning\n    - Hit Enter to enable Dockerfile linting\n    - Hit Enter to select default health endpoint `/`\n    - Open the url to see the pipeline running in the OpenShift Console\n\n1. Verify that Pipeline Run completed successfully\n    - On the OpenShift web console select **Pipelines**\n    - At the top of the page select your development project/namespace created above (ex. `project01-dev`)\n    - The app pipeline last run status should be **Succeeded**\n        ![Pipeline Run](../images/pipeline-run.jpg)\n\n1. Review the Pipeline Tasks/Stages.\n    - Click on the last run\n        ![Last pipeline run](../images/last-run.jpg)\n    - Click on the **Test** task and view the logs\n        ![Test task](../images/test-task.jpg)\n    - Open SonarQube from Console Link\n    - Open Registry from Console Link\n    - Open Artifactory from Console Link\n\n1. The **gitops** step of the pipeline triggeres Argo CD to deploy the app to QA. Select **Developer** perspective, select project `$TOOLKIT_PROJECT-qa` and then select **Topology** from the Console and verify the application running\n        ![Last pipeline run](../images/deploy-qa.jpg)\n\n1. Open the application route url and try out the application using the swagger UI or append `/app` to the URL to load Web UI for the Application. You can download the this sample [picture](https://raw.githubusercontent.com/IBM/MAX-Object-Detector/master/samples/baby-bear.jpg) to test the app\n        ![open url](../images/open-url.jpg)\n        ![ai app](../images/ai-app-baby-bear.jpg)\n\n\n1. Make a change to the application in the git repository and see the pipeline running again from the Console. Lets chagne the Machine Learning being used from `ssd_mobilenet_v1` to `faster_rcnn_resnet101`\n    ```bash\n    git config --local user.email \"${TOOLKIT_USERNAME}@example.com\"\n    git config --local user.name \"${TOOLKIT_USERNAME}\"\n    sed -i 's/ssd_mobilenet_v1/faster_rcnn_resnet101/' Dockerfile\n    git add .\n    git commit -m \"update model\"\n    git push -u origin master\n\n    ```\n\n1. Verify that change in Git Server and Git WebHook\n    - Open Git Dev from Console Link\n    - Navigate to user app git repository\n    - Review the recent commit\n    - Review the webhook recent delivery\n        ![webhood](../images/webhook.jpg)\n\n1. Verify that a new Pipeline starts successfully\n\n1. Verify that the App manifests are being updated in the `gitops` repo in the git account `toolkit` under the `qa` directory.\n    - Open Git Ops from Console Link\n    - Select toolkit/gitops git repository\n        ![gitops](../images/gitops.jpg)\n\n1. Congratulations you finished this lab, continue with lab [Promote an Application using CD with GitOps and ArgoCD](./cd)\n\n\n\n\n","type":"Mdx","contentDigest":"e964341dac5aea6610f9be2abd43b875","counter":1123,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Workshop - Deploy an Artificial Intelligence Microservice"},"exports":{},"rawBody":"---\ntitle: Workshop - Deploy an Artificial Intelligence Microservice\n---\n\nimport Globals from 'gatsby-theme-carbon/src/templates/Globals';\n\n<PageDescription>\n\nDeploy an Artificial Intelligence Microservice\n\n</PageDescription>\n\n1. Prerequisites\n    - The instructor should [Setup Workshop Environment](/workshop/setup)\n    - The student should [Setup CLI and Terminal Shell](/workshop/terminal)\n\n1. Instructor will provide the following info:\n    - OpenShift Console URL (OCP_CONSOLE_URL)\n    - The username and password for OpenShift and Git Server (default values are user01, user02, etc.. for users and `password` for password).\n\n1. Set `TOOLKIT_USERNAME` environment variable.\n   If you are participation in a workshop replace `userdemo` with your assigned username (ex. `user01`).\n    ```bash\n    TOOLKIT_USERNAME=userdemo\n    ```\n\n1. Login to OpenShift using `oc`\n    - If using IBM Cloud cluster then login with your IBM account email and IAM API Key or Token by using the **Copy Login Command**\n        ![Login](../images/login.jpg)\n    - If using a cluster that was configured with the workshop scripts outside IBM Cloud then use respective assigned username (ex. `user01`), and the password is `password`\n    ```bash\n    oc login $OCP_URL -u $TOOLKIT_USERNAME -p password\n    ```\n\n1. Set `TOOLKIT_PROJECT` environment variable\n   If you are participation in a workshop replace `projectdemo` based on your assigned username (ex. `project01`).\n    ```bash\n    TOOLKIT_PROJECT=projectdemo\n    ```\n\n1. Create a project/namespace using your project as prefix, and `-dev` and suffix\n    ```bash\n    oc sync $TOOLKIT_PROJECT-dev\n    ```\n\n1. Fork application template git repo\n    - Open Developer Dashboard from the OpenShift Console\n        ![Developer Dashboard](../images/developer-dashboard.jpg)\n    - Select Starter Kits\n        ![Starter Kits](../images/starter-kits-ai.jpg)\n    - Select One in our case **Artificial Intelligence Microservice**\n    - Click Fork\n    - Login into GIT Sever using the provided username and password (ie `userdemo` and `password`)\n    - Click **Fork Repository**\n\n1. Setup environment variable `GIT_URL` for the git url using the value from previous step or as following.\n        **Note:** We are including username/password in git url for simplicity of this lab. You would **NOT** want to do this in your development environment.\n    ```bash\n    GIT_REPO=ai-model-object-detector\n    GIT_URL=http://${TOOLKIT_USERNAME}:password@$(oc get route -n tools gogs --template='{{.spec.host}}')/${TOOLKIT_USERNAME}/${GIT_REPO}\n    echo GIT_URL=${GIT_URL}\n\n    ```\n\n1. Clone the git repository and change directory\n    ```bash\n    cd $HOME\n    git clone $GIT_URL app\n    cd app\n\n    ```\n\n1. Create a Tekton pipeline for the application\n    ```bash\n    oc pipeline --tekton\n    ```\n    - Use down/up arrow and select `ibm-general`\n    - Enter **n** and hit Enter to disable image scanning\n    - Hit Enter to enable Dockerfile linting\n    - Hit Enter to select default health endpoint `/`\n    - Open the url to see the pipeline running in the OpenShift Console\n\n1. Verify that Pipeline Run completed successfully\n    - On the OpenShift web console select **Pipelines**\n    - At the top of the page select your development project/namespace created above (ex. `project01-dev`)\n    - The app pipeline last run status should be **Succeeded**\n        ![Pipeline Run](../images/pipeline-run.jpg)\n\n1. Review the Pipeline Tasks/Stages.\n    - Click on the last run\n        ![Last pipeline run](../images/last-run.jpg)\n    - Click on the **Test** task and view the logs\n        ![Test task](../images/test-task.jpg)\n    - Open SonarQube from Console Link\n    - Open Registry from Console Link\n    - Open Artifactory from Console Link\n\n1. The **gitops** step of the pipeline triggeres Argo CD to deploy the app to QA. Select **Developer** perspective, select project `$TOOLKIT_PROJECT-qa` and then select **Topology** from the Console and verify the application running\n        ![Last pipeline run](../images/deploy-qa.jpg)\n\n1. Open the application route url and try out the application using the swagger UI or append `/app` to the URL to load Web UI for the Application. You can download the this sample [picture](https://raw.githubusercontent.com/IBM/MAX-Object-Detector/master/samples/baby-bear.jpg) to test the app\n        ![open url](../images/open-url.jpg)\n        ![ai app](../images/ai-app-baby-bear.jpg)\n\n\n1. Make a change to the application in the git repository and see the pipeline running again from the Console. Lets chagne the Machine Learning being used from `ssd_mobilenet_v1` to `faster_rcnn_resnet101`\n    ```bash\n    git config --local user.email \"${TOOLKIT_USERNAME}@example.com\"\n    git config --local user.name \"${TOOLKIT_USERNAME}\"\n    sed -i 's/ssd_mobilenet_v1/faster_rcnn_resnet101/' Dockerfile\n    git add .\n    git commit -m \"update model\"\n    git push -u origin master\n\n    ```\n\n1. Verify that change in Git Server and Git WebHook\n    - Open Git Dev from Console Link\n    - Navigate to user app git repository\n    - Review the recent commit\n    - Review the webhook recent delivery\n        ![webhood](../images/webhook.jpg)\n\n1. Verify that a new Pipeline starts successfully\n\n1. Verify that the App manifests are being updated in the `gitops` repo in the git account `toolkit` under the `qa` directory.\n    - Open Git Ops from Console Link\n    - Select toolkit/gitops git repository\n        ![gitops](../images/gitops.jpg)\n\n1. Congratulations you finished this lab, continue with lab [Promote an Application using CD with GitOps and ArgoCD](./cd)\n\n\n\n\n","fileAbsolutePath":"/home/runner/work/ibm-garage-developer-guide/ibm-garage-developer-guide/src/pages/workshop/ai/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1317950067","1317950067","1364590287","2102389209","2102389209","223705900","3273249464","530240012","530240012","768070550"]}